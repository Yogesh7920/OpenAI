# OpenAI_GYM

This project aims to solve any **OpenAI gym** problems using **DQN and NEAT**.
This project consists of 2 sub-dir.

For any gym environment just change the input and output and watch the AI conquer the game.
For NEAT one can change the input and output in the config file.
For RL one can change the input and output in the class Agent inside agent.py

#### Observations:

The **NEAT** Algorithms is better and faster than **DQN**.

###### Examples:
    1.Cartpole-v0 - 195 avg after 400 episodes in DQN.
    2.Cartpole-v1 - 490 avg after 100 generations in NEAT.
    3.MountainCar - -110 avg after 100 generations in NEAT.
   
## HAVE FUN TWEAKING AND PLAYING WITH THE AI.
